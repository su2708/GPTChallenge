{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 챌린지\n",
    "---\n",
    "(EN)\n",
    "- Implement an LCEL chain with a memory that uses one of the memory classes we learned about.\n",
    "- The chain should take the title of a movie and reply with three emojis that represent the movie. (i.e \"Top Gun\" -> \"🛩️👨‍✈️🔥\". \"The Godfather\" -> \"👨‍👨‍👦🔫🍝 \").\n",
    "- Provide examples to the chain using FewShotPromptTemplate or FewShotChatMessagePromptTemplate to make sure it always replies with three emojis.\n",
    "- To check that the memory is working ask the chain about two movies and then in another cell ask the chain to tell you what is the movie you asked about first.\n",
    "\n",
    "(KR)\n",
    "- 앞서 배운 메모리 클래스 중 하나를 사용하는 메모리로 LCEL 체인을 구현합니다.\n",
    "- 이 체인은 영화 제목을 가져와 영화를 나타내는 세 개의 이모티콘으로 응답해야 합니다. (예: \"탑건\" -> \"🛩️👨‍✈️🔥\". \"대부\" -> \"👨‍👨‍👦🔫🍝\").\n",
    "- 항상 세 개의 이모티콘으로 답장하도록 FewShotPromptTemplate 또는 FewShotChatMessagePromptTemplate을 사용하여 체인에 예시를 제공하세요.\n",
    "- 메모리가 작동하는지 확인하려면 체인에 두 개의 영화에 대해 질문한 다음 다른 셀에서 체인에 먼저 질문한 영화가 무엇인지 알려달라고 요청하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts.few_shot import FewShotChatMessagePromptTemplate\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.memory import ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0.1)\n",
    "\n",
    "memory = ConversationBufferMemory()\n",
    "\n",
    "# Few-shot examples\n",
    "examples = [\n",
    "    {\"movie\": \"Titanic\", \"emoji\": \"🚢💑💔\"},\n",
    "    {\"movie\": \"Jurassic Park\", \"emoji\": \"🦖🌿🚙\"},\n",
    "    {\"movie\": \"Harry Potter\", \"emoji\": \"🧙‍♂️⚡📖\"}\n",
    "]\n",
    "\n",
    "# Example prompt\n",
    "example_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"human\", \"{movie}\"),\n",
    "    (\"ai\", \"{emoji}\")\n",
    "])\n",
    "\n",
    "# FewShotChatMessagePromptTemplate 적용\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    examples=examples\n",
    ")\n",
    "\n",
    "# FewShot 예제 부분을 문자열로 변환\n",
    "formatted_few_shot = \"\\n\".join(\n",
    "    [f\"Human: {ex['movie']}\\nAI: {ex['emoji']}\" for ex in examples]\n",
    ")\n",
    "\n",
    "final_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", f\"\"\"\n",
    "    Here are some examples of movies and their corresponding emojis:\\n\\n{formatted_few_shot}\\n\\n. If the last human question is one of the movie titles, respond with exactly three emoticons. If the question is about remembering the movie you asked, respond with the movie you asked. Except for the examples above, you should respond based on your chat history.\n",
    "    \"\"\"),\n",
    "    MessagesPlaceholder(variable_name=\"history\"),\n",
    "    (\"human\", \"{question}\")\n",
    "])\n",
    "\n",
    "def load_memory(_):\n",
    "    \"\"\"메모리에서 저장된 대화를 불러와 LangChain 메시지 형식으로 변환\"\"\"\n",
    "    history = memory.load_memory_variables({}).get(\"history\", [])\n",
    "    return history if isinstance(history, list) else []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = RunnablePassthrough.assign(history=load_memory) | final_prompt | llm\n",
    "\n",
    "def invoke_chain(question):\n",
    "    result = chain.invoke({\"question\": question})\n",
    "    memory.save_context({\"input\": question}, {\"output\": result.content})\n",
    "    print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🕰️🧠🌌\n",
      "🕶️💊🤖\n"
     ]
    }
   ],
   "source": [
    "# 테스트 실행\n",
    "invoke_chain(\"Inception\")\n",
    "invoke_chain(\"The Matrix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'history': 'Human: Inception\\nAI: 🕰️🧠🌌\\nHuman: The Matrix\\nAI: 🕶️💊🤖'}\n"
     ]
    }
   ],
   "source": [
    "# 메모리 확인\n",
    "print(memory.load_memory_variables({}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The movie you asked about before 'The Matrix' was 'Jurassic Park'. 🦖🌿🚙\n"
     ]
    }
   ],
   "source": [
    "invoke_chain(\"What was the movie I asked about before 'The Matrix'?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GPTChallenge",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
