{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ì±Œë¦°ì§€\n",
    "---\n",
    "(EN)\n",
    "- Implement an LCEL chain with a memory that uses one of the memory classes we learned about.\n",
    "- The chain should take the title of a movie and reply with three emojis that represent the movie. (i.e \"Top Gun\" -> \"ğŸ›©ï¸ğŸ‘¨â€âœˆï¸ğŸ”¥\". \"The Godfather\" -> \"ğŸ‘¨â€ğŸ‘¨â€ğŸ‘¦ğŸ”«ğŸ \").\n",
    "- Provide examples to the chain using FewShotPromptTemplate or FewShotChatMessagePromptTemplate to make sure it always replies with three emojis.\n",
    "- To check that the memory is working ask the chain about two movies and then in another cell ask the chain to tell you what is the movie you asked about first.\n",
    "\n",
    "(KR)\n",
    "- ì•ì„œ ë°°ìš´ ë©”ëª¨ë¦¬ í´ë˜ìŠ¤ ì¤‘ í•˜ë‚˜ë¥¼ ì‚¬ìš©í•˜ëŠ” ë©”ëª¨ë¦¬ë¡œ LCEL ì²´ì¸ì„ êµ¬í˜„í•©ë‹ˆë‹¤.\n",
    "- ì´ ì²´ì¸ì€ ì˜í™” ì œëª©ì„ ê°€ì ¸ì™€ ì˜í™”ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ì„¸ ê°œì˜ ì´ëª¨í‹°ì½˜ìœ¼ë¡œ ì‘ë‹µí•´ì•¼ í•©ë‹ˆë‹¤. (ì˜ˆ: \"íƒ‘ê±´\" -> \"ğŸ›©ï¸ğŸ‘¨â€âœˆï¸ğŸ”¥\". \"ëŒ€ë¶€\" -> \"ğŸ‘¨â€ğŸ‘¨â€ğŸ‘¦ğŸ”«ğŸ\").\n",
    "- í•­ìƒ ì„¸ ê°œì˜ ì´ëª¨í‹°ì½˜ìœ¼ë¡œ ë‹µì¥í•˜ë„ë¡ FewShotPromptTemplate ë˜ëŠ” FewShotChatMessagePromptTemplateì„ ì‚¬ìš©í•˜ì—¬ ì²´ì¸ì— ì˜ˆì‹œë¥¼ ì œê³µí•˜ì„¸ìš”.\n",
    "- ë©”ëª¨ë¦¬ê°€ ì‘ë™í•˜ëŠ”ì§€ í™•ì¸í•˜ë ¤ë©´ ì²´ì¸ì— ë‘ ê°œì˜ ì˜í™”ì— ëŒ€í•´ ì§ˆë¬¸í•œ ë‹¤ìŒ ë‹¤ë¥¸ ì…€ì—ì„œ ì²´ì¸ì— ë¨¼ì € ì§ˆë¬¸í•œ ì˜í™”ê°€ ë¬´ì—‡ì¸ì§€ ì•Œë ¤ë‹¬ë¼ê³  ìš”ì²­í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts.few_shot import FewShotChatMessagePromptTemplate\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.memory import ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0.1)\n",
    "\n",
    "memory = ConversationBufferMemory()\n",
    "\n",
    "# Few-shot examples\n",
    "examples = [\n",
    "    {\"movie\": \"Titanic\", \"emoji\": \"ğŸš¢ğŸ’‘ğŸ’”\"},\n",
    "    {\"movie\": \"Jurassic Park\", \"emoji\": \"ğŸ¦–ğŸŒ¿ğŸš™\"},\n",
    "    {\"movie\": \"Harry Potter\", \"emoji\": \"ğŸ§™â€â™‚ï¸âš¡ğŸ“–\"}\n",
    "]\n",
    "\n",
    "# Example prompt\n",
    "example_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"human\", \"{movie}\"),\n",
    "    (\"ai\", \"{emoji}\")\n",
    "])\n",
    "\n",
    "# FewShotChatMessagePromptTemplate ì ìš©\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    examples=examples\n",
    ")\n",
    "\n",
    "# FewShot ì˜ˆì œ ë¶€ë¶„ì„ ë¬¸ìì—´ë¡œ ë³€í™˜\n",
    "formatted_few_shot = \"\\n\".join(\n",
    "    [f\"Human: {ex['movie']}\\nAI: {ex['emoji']}\" for ex in examples]\n",
    ")\n",
    "\n",
    "final_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", f\"\"\"\n",
    "    Here are some examples of movies and their corresponding emojis:\\n\\n{formatted_few_shot}\\n\\n. If the last human question is one of the movie titles, respond with exactly three emoticons. If the question is about remembering the movie you asked, respond with the movie you asked. Except for the examples above, you should respond based on your chat history.\n",
    "    \"\"\"),\n",
    "    MessagesPlaceholder(variable_name=\"history\"),\n",
    "    (\"human\", \"{question}\")\n",
    "])\n",
    "\n",
    "def load_memory(_):\n",
    "    \"\"\"ë©”ëª¨ë¦¬ì—ì„œ ì €ì¥ëœ ëŒ€í™”ë¥¼ ë¶ˆëŸ¬ì™€ LangChain ë©”ì‹œì§€ í˜•ì‹ìœ¼ë¡œ ë³€í™˜\"\"\"\n",
    "    history = memory.load_memory_variables({}).get(\"history\", [])\n",
    "    return history if isinstance(history, list) else []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = RunnablePassthrough.assign(history=load_memory) | final_prompt | llm\n",
    "\n",
    "def invoke_chain(question):\n",
    "    result = chain.invoke({\"question\": question})\n",
    "    memory.save_context({\"input\": question}, {\"output\": result.content})\n",
    "    print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ•°ï¸ğŸ§ ğŸŒŒ\n",
      "ğŸ•¶ï¸ğŸ’ŠğŸ¤–\n"
     ]
    }
   ],
   "source": [
    "# í…ŒìŠ¤íŠ¸ ì‹¤í–‰\n",
    "invoke_chain(\"Inception\")\n",
    "invoke_chain(\"The Matrix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'history': 'Human: Inception\\nAI: ğŸ•°ï¸ğŸ§ ğŸŒŒ\\nHuman: The Matrix\\nAI: ğŸ•¶ï¸ğŸ’ŠğŸ¤–'}\n"
     ]
    }
   ],
   "source": [
    "# ë©”ëª¨ë¦¬ í™•ì¸\n",
    "print(memory.load_memory_variables({}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The movie you asked about before 'The Matrix' was 'Jurassic Park'. ğŸ¦–ğŸŒ¿ğŸš™\n"
     ]
    }
   ],
   "source": [
    "invoke_chain(\"What was the movie I asked about before 'The Matrix'?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GPTChallenge",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
