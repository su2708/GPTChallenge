{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 챌린지\n",
    "---\n",
    "(EN)\n",
    "- Implement a complete RAG pipeline with a Stuff Documents chain.\n",
    "- You must implement the chain manually.\n",
    "- Give a ConversationBufferMemory to the chain.\n",
    "- Use this document to perform RAG: https://gist.github.com/serranoarevalo/5acf755c2b8d83f1707ef266b82ea223\n",
    "- Ask the following questions to the chain:\n",
    "    - Is Aaronson guilty?\n",
    "    - What message did he write in the table?\n",
    "    - Who is Julia?\n",
    "\n",
    "(KR)\n",
    "- Stuff Documents 체인을 사용하여 완전한 RAG 파이프라인을 구현하세요.\n",
    "- 체인을 수동으로 구현해야 합니다.\n",
    "- 체인에 ConversationBufferMemory를 부여합니다.\n",
    "- 이 문서를 사용하여 RAG를 수행하세요: https://gist.github.com/serranoarevalo/5acf755c2b8d83f1707ef266b82ea223\n",
    "- 체인에 다음 질문을 합니다:\n",
    "    - Aaronson 은 유죄인가요?\n",
    "    - 그가 테이블에 어떤 메시지를 썼나요?\n",
    "    - Julia 는 누구인가요?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: libmagic is unavailable but assists in filetype detection. Please consider installing libmagic for better results.\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_unstructured import UnstructuredLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.embeddings import CacheBackedEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.storage import LocalFileStore\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.schema.runnable import RunnableLambda\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0.1,\n",
    ")\n",
    "\n",
    "memory = ConversationBufferMemory(\n",
    "    llm=llm,\n",
    "    return_messages=True\n",
    ")\n",
    "\n",
    "# 캐시 저장 경로\n",
    "cache_dir = LocalFileStore(\"./.cache/\")\n",
    "\n",
    "# Tiktoken: OpenAI에서 만든 tokenization library.\n",
    "splitter = CharacterTextSplitter.from_tiktoken_encoder(\n",
    "    separator=\"\\n\",\n",
    "    chunk_size=950,\n",
    "    chunk_overlap=100,\n",
    ")\n",
    "\n",
    "loader = UnstructuredLoader('./files/document.txt')\n",
    "\n",
    "docs = loader.load_and_split(text_splitter=splitter)\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "# 중복 요청 시 캐시된 결과를 반환\n",
    "cached_embeddings = CacheBackedEmbeddings.from_bytes_store(\n",
    "    embeddings, cache_dir\n",
    ")\n",
    "\n",
    "# FAISS 라이브러리로 캐시에서 임베딩 벡터 검색\n",
    "vectorstore = FAISS.from_documents(docs, cached_embeddings)\n",
    "\n",
    "# docs를 불러오는 역할\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant. Answer questions using only the following context. If you don't know the answer, just say you don't know. Don't make it up:\\n\\n{context}\"),\n",
    "    MessagesPlaceholder(variable_name=\"history\"),\n",
    "    (\"human\", \"{question}\")\n",
    "])\n",
    "\n",
    "def prepare_inputs(inputs):\n",
    "    query = inputs[\"question\"]\n",
    "    retrieved_docs = retriever.get_relevant_documents(query)\n",
    "    context_text = \"\\n\\n\".join([doc.page_content for doc in retrieved_docs])\n",
    "    \n",
    "    return {\n",
    "        \"context\": context_text,\n",
    "        \"history\": memory.load_memory_variables({})[\"history\"],\n",
    "        \"question\": query\n",
    "    }\n",
    "\n",
    "# CASE: chain_type = 'stuff' (default)\n",
    "chain = RunnableLambda(prepare_inputs) | prompt | llm\n",
    "\n",
    "def invoke_chain(question):\n",
    "    response = chain.invoke({\"question\": question})\n",
    "    memory.save_context({\"input\": question}, {\"output\": response.content})\n",
    "    print(f\"{response.content}\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "He accepted everything. The past was alterable. The past never had been altered. Oceania was at war with Eastasia. Oceania had always been at war with Eastasia. Jones, Aaronson, and Rutherford were guilty of the crimes they were charged with. He had never seen the photograph that disproved their guilt. It had never existed, he had invented it. He remembered remembering contrary things, but those were false memories, products of self-deception. How easy it all was! Only surrender, and everything else followed. It was like swimming against a current that swept you backwards however hard you struggled, and then suddenly deciding to turn round and go with the current instead of opposing it. Nothing had changed except your own attitude: the predestined thing happened in any case. He hardly knew why he had ever rebelled. Everything was easy, except----!\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DOWN WITH BIG BROTHER\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Julia is a character in the novel who is involved in a forbidden romantic relationship with the protagonist.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "invoke_chain(\"Is Aaronson guilty?\")\n",
    "invoke_chain(\"What message did he write in the table?\")\n",
    "invoke_chain(\"Who is Julia?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 정답코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.embeddings import CacheBackedEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.storage import LocalFileStore\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0.1,\n",
    ")\n",
    "\n",
    "cache_dir = LocalFileStore(\"./.cache/\")\n",
    "\n",
    "splitter = CharacterTextSplitter.from_tiktoken_encoder(\n",
    "    separator=\"\\n\",\n",
    "    chunk_size=600,\n",
    "    chunk_overlap=100,\n",
    ")\n",
    "\n",
    "loader = TextLoader(\"./files/document.txt\")\n",
    "\n",
    "docs = loader.load_and_split(text_splitter=splitter)\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "cached_embeddings = CacheBackedEmbeddings.from_bytes_store(embeddings, cache_dir)\n",
    "\n",
    "vectorstore = FAISS.from_documents(docs, cached_embeddings)\n",
    "\n",
    "memory = ConversationBufferMemory(\n",
    "    llm=llm,\n",
    "    max_token_limit=20,\n",
    "    return_messages=True,\n",
    ")\n",
    "\n",
    "def load_memory(_):\n",
    "    return memory.load_memory_variables({})[\"history\"]\n",
    "\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant. Answer questions using only the following context. If you don't know the answer just say you don't know, don't make it up:\\n\\n{context}\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"history\"),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = (\n",
    "    {\n",
    "        \"context\": retriever,\n",
    "        \"question\": RunnablePassthrough(),\n",
    "        \"history\": load_memory,\n",
    "    }\n",
    "    | prompt\n",
    "    | llm\n",
    ")\n",
    "\n",
    "def invoke_chain(question):\n",
    "    result = chain.invoke(question)\n",
    "    print(result.content)\n",
    "    memory.save_context({\"input\": question}, {\"output\": result.content})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "According to the document, Jones, Aaronson, and Rutherford were guilty of the crimes they were charged with.\n",
      "He wrote \"FREEDOM IS SLAVERY\" and then \"TWO AND TWO MAKE FIVE\" on the table.\n",
      "Julia is a character in the document who was involved with Winston in a forbidden relationship.\n"
     ]
    }
   ],
   "source": [
    "invoke_chain(\"Is Aaronson guilty?\")\n",
    "invoke_chain(\"What message did he write in the table?\")\n",
    "invoke_chain(\"Who is Julia?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Is Aaronson guilty?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='According to the document, Jones, Aaronson, and Rutherford were guilty of the crimes they were charged with.', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='What message did he write in the table?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='He wrote \"FREEDOM IS SLAVERY\" and then \"TWO AND TWO MAKE FIVE\" on the table.', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Who is Julia?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Julia is a character in the document who was involved with Winston in a forbidden relationship.', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_memory({})\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GPTChallenge",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
